{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_curve, auc, confusion_matrix\n",
    ")\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier  \n",
    "#import xgboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PREPROCESSING:\n",
    "  \n",
    "    def __init__(self,train_data_path, item_data_path,test_data_path):\n",
    "        '''\n",
    "    \n",
    "        This class give information about the datasets\n",
    "    \n",
    "        '''\n",
    "        self.df_train = pd.read_csv(train_data_path)\n",
    "        self.df_item = pd.read_csv(item_data_path)\n",
    "        self.df_test = pd.read_csv(test_data_path)\n",
    "        \n",
    "    def handle_duplicates_complete(self):\n",
    "        '''\n",
    "        \n",
    "        This method handles the duplicates in the datasets\n",
    "        \n",
    "        '''\n",
    "        self.df_train_duplicate_handled = self.df_train.drop_duplicates()\n",
    "        self.df_item_duplicate_handled = self.df_item.drop_duplicates()\n",
    "        self.df_test_duplicate_handled = self.df_test.drop_duplicates()\n",
    "    def check_missing_value(self):\n",
    "        '''\n",
    "        \n",
    "        Check if there are any missing values\n",
    "        \n",
    "        '''    \n",
    "        \n",
    "        self.df_train_missing_values = self.df_train_duplicate_handled.isnull().sum()\n",
    "        self.df_item_missing_values = self.df_item_duplicate_handled.isnull().sum()\n",
    "        self.df_test_missing_values = self.df_test_duplicate_handled.isnull().sum()\n",
    "    def transform_date(self):\n",
    "        '''\n",
    "        \n",
    "        Transform object to datetime type for 'ymd'\n",
    "        \n",
    "        '''    \n",
    "        self.df_train_date_transformed = self.df_train_duplicate_handled.copy()\n",
    "        self.df_train_date_transformed['ymd'] = pd.to_datetime(self.df_train_duplicate_handled['ymd'])   \n",
    "        self.df_test_date_transformed = self.df_test_duplicate_handled.copy()\n",
    "        self.df_test_date_transformed['ymd'] = pd.to_datetime(self.df_test_duplicate_handled['ymd'])\n",
    "    def encode_categorical_features(self):\n",
    "        '''\n",
    "        \n",
    "        Label encode 'platform' because it has 13 unique values \n",
    "        and \n",
    "        map 'device' with 0 or 1 because it has just 2 unique values 'DESKTOP' and 'MOBILE'\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        self.df_train_encoded = self.df_train_date_transformed.copy()\n",
    "        self.df_test_encoded = self.df_test_date_transformed.copy()\n",
    "        self.df_train_encoded['platform'] = label_encoder.fit_transform(self.df_train_encoded['platform'])\n",
    "        self.df_test_encoded['platform'] = label_encoder.fit_transform(self.df_test_encoded['platform'])\n",
    "        binary_mapping ={'MOBILE':0,'DESKTOP':1}\n",
    "        self.df_train_encoded['device'] =self.df_train_encoded['device'].map(binary_mapping)\n",
    "        self.df_test_encoded['device']=self.df_test_encoded['device'].map(binary_mapping)\n",
    "        \n",
    "    def merge_data(self):\n",
    "        '''\n",
    "        \n",
    "        Merge Train data with additional information provided by item data with inner join to have complete set and \n",
    "        left join to include all item_id in train and test set.\n",
    "        \n",
    "        '''\n",
    "        '''\n",
    "        Known Items alone in train\n",
    "        '''\n",
    "        self.df_merged_with_known_item_info = pd.merge(self.df_train_encoded,self.df_item_duplicate_handled,on='item_id')\n",
    "        self.df_merged_with_known_item_info['ymd']= pd.to_datetime(self.df_merged_with_known_item_info['ymd'],errors ='coerce')\n",
    "        self.df_merged_with_known_item_info['day_of_week'] = self.df_merged_with_known_item_info['ymd'].dt.dayofweek\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        With all items in train\n",
    "        \n",
    "        '''\n",
    "        self.df_merged_train = pd.merge(self.df_train_encoded,self.df_item_duplicate_handled,on='item_id',how='left')\n",
    "        self.df_merged_train['ymd']= pd.to_datetime(self.df_merged_train['ymd'],errors ='coerce')\n",
    "        self.df_merged_train['day_of_week'] = self.df_merged_train['ymd'].dt.dayofweek \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        With all items in test\n",
    "        \n",
    "        '''\n",
    "        self.df_merged_test = pd.merge(self.df_test_encoded,self.df_item_duplicate_handled,on='item_id',how='left')\n",
    "        self.df_merged_test['ymd']= pd.to_datetime(self.df_merged_test['ymd'],errors ='coerce')\n",
    "        self.df_merged_test['day_of_week'] = self.df_merged_test['ymd'].dt.dayofweek \n",
    "        \n",
    "    def check_feature_importance(self):\n",
    "        '''\n",
    "        \n",
    "        Check feature importance using Random Forest with known item info in train set\n",
    "        \n",
    "        '''  \n",
    "        self.df_features = self.df_merged_with_known_item_info.drop(columns=['is_clicked_item','ymd']) \n",
    "        self.df_truth = self.df_merged_with_known_item_info['is_clicked_item']\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state = 42)\n",
    "        rf.fit(self.df_features,self.df_truth)\n",
    "        self.importance = rf.feature_importances_\n",
    "        \n",
    "    def missing_values_after_merging(self):\n",
    "        '''\n",
    "        \n",
    "        Check the missing values after merging the dataset\n",
    "        \n",
    "        '''    \n",
    "        self.missing_items = self.df_merged_train[self.df_merged_train['star'].isnull()]['item_id']\n",
    "    def handle_missing_values(self):\n",
    "        '''\n",
    "        \n",
    "        Handle the missing values after merging the information regarding item\n",
    "        \n",
    "        '''   \n",
    "        self.df_merged_train_missing_value_handled = self.df_merged_train.copy()\n",
    "        self.df_merged_test_missing_value_handled = self.df_merged_test.copy()\n",
    "        '''\n",
    "        Mode for 'star'\n",
    "        '''\n",
    "        # Train set\n",
    "        self.train_star_mode = self.df_merged_train['star'].mode()[0]  \n",
    "        self.df_merged_train_missing_value_handled.loc[self.df_merged_train_missing_value_handled['star'].isnull(),'star'] = self.train_star_mode\n",
    "        # Test Set\n",
    "        self.test_star_mode = self.df_merged_test['star'].mode()[0]  \n",
    "        self.df_merged_test_missing_value_handled.loc[self.df_merged_test_missing_value_handled['star'].isnull(),'star'] = self.test_star_mode\n",
    "        '''\n",
    "        Median for 'num_rating'\n",
    "        \n",
    "        '''\n",
    "        # Train set\n",
    "        self.train_num_rating_median = self.df_merged_train['num_rating'].median()\n",
    "        self.df_merged_train_missing_value_handled.loc[self.df_merged_train_missing_value_handled['num_rating'].isnull(),'num_rating'] = self.train_num_rating_median\n",
    "        \n",
    "        # Test set\n",
    "        self.test_num_rating_median = self.df_merged_test['num_rating'].median()\n",
    "        self.df_merged_test_missing_value_handled.loc[self.df_merged_test_missing_value_handled['num_rating'].isnull(),'num_rating'] = self.test_num_rating_median\n",
    "        '''\n",
    "        Median for 'avg_rating'\n",
    "        '''\n",
    "        # Train set\n",
    "        self.train_avg_rating_median = self.df_merged_train['avg_rating'].median()\n",
    "        self.df_merged_train_missing_value_handled.loc[self.df_merged_train_missing_value_handled['avg_rating'].isnull(),'avg_rating'] = self.train_avg_rating_median\n",
    "        # Test set\n",
    "        self.test_avg_rating_median = self.df_merged_test['avg_rating'].median()\n",
    "        self.df_merged_test_missing_value_handled.loc[self.df_merged_test_missing_value_handled['avg_rating'].isnull(),'avg_rating'] = self.test_avg_rating_median\n",
    "        \n",
    "        '''\n",
    "        use Mode for 'type_id' since has a dominant mode\n",
    "        \n",
    "        '''\n",
    "        # Train set\n",
    "        self.train_type_id_mode = self.df_merged_train['type_id'].mode()[0]\n",
    "        self.df_merged_train_missing_value_handled.loc[self.df_merged_train_missing_value_handled['type_id'].isnull(),'type_id'] = self.train_type_id_mode\n",
    "        \n",
    "        # Test set\n",
    "        self.test_type_id_mode = self.df_merged_test['type_id'].mode()[0]\n",
    "        self.df_merged_test_missing_value_handled.loc[self.df_merged_test_missing_value_handled['type_id'].isnull(),'type_id'] = self.test_type_id_mode\n",
    "        '''\n",
    "        \n",
    "        'city_id' can also be filled using mode value since it is a categorical value\n",
    "        \n",
    "        '''\n",
    "        # Train set\n",
    "        self.train_city_id_mode = self.df_merged_train['city_id'].mode()[0]\n",
    "        self.df_merged_train_missing_value_handled.loc[self.df_merged_train_missing_value_handled['city_id'].isnull(),'city_id'] = self.train_city_id_mode\n",
    "        # Test set\n",
    "        self.test_city_id_mode = self.df_merged_test['city_id'].mode()[0]\n",
    "        self.df_merged_test_missing_value_handled.loc[self.df_merged_test_missing_value_handled['city_id'].isnull(),'city_id'] = self.test_city_id_mode\n",
    "    def scale_numerical_features(self):\n",
    "        '''\n",
    "       \n",
    "        Scale numerical features using standardscaler \n",
    "       \n",
    "        '''\n",
    "        # Train set\n",
    "        self.df_scaled = self.df_merged_train_missing_value_handled.copy()\n",
    "        self.num_columns= ['price','num_rating','avg_rating']\n",
    "        self.df_num_data= self.df_merged_train_missing_value_handled[self.num_columns]\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaled_num_data = scaler.fit_transform(self.df_num_data)\n",
    "        self.df_scaled[self.num_columns] = pd.DataFrame(self.scaled_num_data, columns=self.num_columns)\n",
    "        \n",
    "        # Test set\n",
    "        self.df_test_scaled = self.df_merged_test_missing_value_handled.copy()\n",
    "        self.df_test_num_data= self.df_merged_test_missing_value_handled[self.num_columns]\n",
    "        self.scaled_test_num_data = scaler.fit_transform(self.df_test_num_data)\n",
    "        self.df_test_scaled[self.num_columns] = pd.DataFrame(self.scaled_test_num_data, columns=self.num_columns)\n",
    "    def frequency_encode(self,id_columns,df):\n",
    "        '''\n",
    "        \n",
    "        Encode all id's with frequency encoding because of high cardinality\n",
    "        \n",
    "        Also encode 'platform' and 'item_position' which are having high cardinality\n",
    "        \n",
    "        '''   \n",
    "        # Train set\n",
    "        self.id_columns = ['user_id','search_id','item_id','city_id','type_id','platform','item_position']\n",
    "        id_columns =  self.id_columns\n",
    "        self.df_id_data= self.df_scaled[self.id_columns]\n",
    "        df= self.df_id_data\n",
    "        for col in id_columns:\n",
    "            freq = df[col].value_counts() / len(df)\n",
    "            df.loc[:, col ] = df[col].map(freq).astype('float64')\n",
    "        self.df_scaled.loc[:,self.id_columns] = df \n",
    "        # Test set\n",
    "        self.df_test_id_data =self.df_test_scaled[self.id_columns]\n",
    "        df_test = self.df_test_id_data\n",
    "        for col in id_columns:\n",
    "            freq_test = df_test[col].value_counts() / len(df_test)\n",
    "            df_test.loc[:,col] = df_test[col].map(freq_test).astype('float64')\n",
    "        self.df_test_scaled.loc[:,self.id_columns] = df_test    \n",
    "    def scale_star(self):\n",
    "        '''\n",
    "        \n",
    "        'star' feature is following a right skewed distribution, so it is better to scale it using log transformation\n",
    "        \n",
    "        '''  \n",
    "        # Train set\n",
    "        self.df_scaled['star'] = (np.log(self.df_scaled['star']+1) -1) \n",
    "        # Test set\n",
    "        self.df_test_scaled['star'] = (np.log(self.df_test_scaled['star']+1)-1)\n",
    "    def scale_day_of_week(self):\n",
    "        '''\n",
    "        \n",
    "        scale day of week using cyclical encoding\n",
    "        \n",
    "        ''' \n",
    "        # Train set\n",
    "        period = 7\n",
    "        self.df_scaled['day_of_week_sin']=(np.sin(2 * np.pi * self.df_scaled['day_of_week'] / period) + 1)/ 2\n",
    "        self.df_scaled['day_of_week_cos']= (np.cos(2* np.pi * self.df_scaled['day_of_week'] / period) + 1)/ 2 \n",
    "        \n",
    "        # Test set\n",
    "        self.df_test_scaled['day_of_week_sin']=(np.sin(2 * np.pi * self.df_test_scaled['day_of_week'] / period) + 1)/ 2\n",
    "        self.df_test_scaled['day_of_week_cos']= (np.cos(2* np.pi * self.df_test_scaled['day_of_week'] / period) + 1)/ 2 \n",
    "    def remove_correlated(self,threshold):\n",
    "        '''\n",
    "        \n",
    "        Remove the correlated columns\n",
    "        \n",
    "        '''   \n",
    "        # Train set\n",
    "        self.df_scaled_features = self.df_scaled.copy()\n",
    "        self.df_label = self.df_scaled.loc[:,['is_clicked_item']]\n",
    "        self.df_scaled_features.drop(columns=['ymd','is_clicked_item','day_of_week'], inplace = True)\n",
    "        self.df_corr = self.df_scaled_features.corr(method='pearson', min_periods=1)\n",
    "        self.df_not_correlated = ~(self.df_corr.mask(np.tril(np.ones([len(self.df_corr)]*2, dtype=bool))).abs() > threshold).any()\n",
    "        self.un_corr_idx = self.df_not_correlated.loc[self.df_not_correlated[self.df_not_correlated.index] == True].index\n",
    "        self.df_uncorr = self.df_scaled_features[self.un_corr_idx]\n",
    "        self.df_uncorr['is_clicked_item']=self.df_label['is_clicked_item']\n",
    "        \n",
    "        # Test\n",
    "        self.df_test_scaled_features = self.df_test_scaled.copy()\n",
    "        self.df_test_uncorr = self.df_test_scaled_features[self.un_corr_idx]\n",
    "    def drop_feature_with_less_importance(self , feature_imp_threshold):\n",
    "        '''\n",
    "        Drop the feature with less importance\n",
    "        \n",
    "        '''\n",
    "        # Train set\n",
    "        self.X = self.df_uncorr[self.df_uncorr.columns[:-1]]\n",
    "        self.y = self.df_uncorr[['is_clicked_item']]\n",
    "        clf = ExtraTreesClassifier(n_estimators=50)\n",
    "        clf = clf.fit(self.X, self.y)\n",
    "        self.feature_imp = clf.feature_importances_  \n",
    "        self.model = SelectFromModel(clf, prefit=True, threshold= feature_imp_threshold)\n",
    "        self.X_new = self.model.transform(self.X)\n",
    "        \n",
    "    def optimal_feature(self): \n",
    "        \"\"\"\n",
    "        Retain the features with importance\n",
    "        \"\"\"\n",
    "        # Train set\n",
    "        self.selected_feature_indices = self.model.get_support()\n",
    "        self.selected_feature_names = self.df_uncorr.columns[:-1][self.selected_feature_indices]\n",
    "        self.df_independent_feature = pd.DataFrame(data=self.X_new, columns=self.selected_feature_names)    \n",
    "        \n",
    "        # Test set\n",
    "        self.df_test_independent_feature = self.df_test_uncorr.loc[:,self.selected_feature_names]\n",
    "    def process(self):\n",
    "        '''\n",
    "        \n",
    "        Process all the methods inside the class\n",
    "        \n",
    "        '''\n",
    "        self.handle_duplicates_complete()\n",
    "        self.check_missing_value()\n",
    "        self.transform_date()\n",
    "        self.encode_categorical_features()\n",
    "        self.merge_data()\n",
    "        self.check_feature_importance()\n",
    "        self.missing_values_after_merging()\n",
    "        self.handle_missing_values()\n",
    "        self.scale_numerical_features()\n",
    "        self.frequency_encode(id_columns,df_id_data)\n",
    "        self.scale_star()\n",
    "        self.scale_day_of_week()\n",
    "        self.remove_correlated(threshold = 0.9)\n",
    "        self.drop_feature_with_less_importance(feature_imp_threshold=0.005)\n",
    "        self.optimal_feature()\n",
    "        return self.df_independent_feature, self.df_label, self.df_test_independent_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = PREPROCESSING('train.csv','item.csv','test.csv')\n",
    "df_independent_feature, df_label,df_test_independent_feature = PP.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. All the datasets are loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_item.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No duplicates are found in the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Missing values are checked in all the all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.Missing values in Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_train = PP.df_train_missing_values\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values_train.plot(kind='bar', color='blue')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values in train set')\n",
    "plt.title('Missing Values in Each Column in train set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.Missing values in Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_item = PP.df_item_missing_values\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values_item.plot(kind='bar', color='blue')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values in item data')\n",
    "plt.title('Missing Values in Each Column in additional information about item')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Missing values in Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_test = PP.df_test_missing_values\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values_test.plot(kind='bar', color='blue')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values in test set')\n",
    "plt.title('Missing Values in Each Column in test set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transformed 'ymd' column to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoded categorical fetaures in train set and test set. 'platform' is encoded using label encoding and 'device' is encoded using mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Merged item information with train set using left join and added an additional column called 'day_of_week' which will be important while booking accomodation. Not all item_id listed in train set not there in item.csv, left join will result in some missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. check the importance of features by making use of an inner joined train.csv and item.csv with no missing values.This will help us check if all columns are important to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': PP.df_features.columns,\n",
    "    'Importance': PP.importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results shows that it is better consider all columns at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Check for missing values which resulted after merging with item.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = PP.df_merged_train.isnull().sum()\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values.plot(kind='bar', color='blue')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.title('Missing Values in Each Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The figure shows that around 20% of data in 'avg_rating', 'star','num_rating','type_id' and 'city_id' are missing. It is not a good idea to drop columns with missing values since it can result in informatation loss. So it is better to handle the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Handle missing values\n",
    "### 'avg_rating' and 'num_rating' are continous values so it is better to impute missing values in these columns using median.\n",
    "### 'star' is an ordinal value so it is better to use mode value for imputing missing values.\n",
    "### 'type_id' and 'city_id' are unique identifiers so we have to check how the data is distributed in those two cases and decide on which method to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for type_id\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='type_id', data=PP.df_merged_with_known_item_info)\n",
    "plt.title('Distribution of Type ID')\n",
    "plt.xlabel('Type ID')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'type_id' clearly have a dominant mode so it is better to impute missing values using mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for city_id\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='city_id', data=PP.df_merged_with_known_item_info)\n",
    "plt.title('Distribution of City ID')\n",
    "plt.xlabel('City ID')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_merged_train_missing_value_handled['city_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case of 'city_id' eventough it does not have a dominant mode being a unique identifier with around 6846 unique values, it is better go with mode value in this case as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'type_id' clearly has mode 2 as since it is a unique identifier it is better to fill missing values corresponding to this column with mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Check Imbalance in 'is_clicked_item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_clicked_item = PP.df_merged_train_missing_value_handled.groupby(['is_clicked_item']).size()\n",
    "count_by_clicked_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_clicked_item.plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Percentage of Class Imbalance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data is clearly imbalanced. It has to considered while training the model. Otherwise sampling methods could also be used but it might result in information loss or can bring overfitting, so better to take care of imbalance while training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the cardinality of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PP.df_merged_train_missing_value_handled.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_merged_train_missing_value_handled.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods used to scale features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. 'price', 'avg_rating','num_rating' are only completely numerical features so standardscaler can be used to scale these features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. 'user_id','search_id','item_id','type_id' and 'city_id' are unique identifiers. 'platform' and item_position are also high cardinality features so all these features acn be frequency encoded rather than scaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. 'star' clearly is an ordinal feature, first visualize how star rating is distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(PP.df_merged_train_missing_value_handled['star'], bins=bins, edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Star Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Star Ratings')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is right skewed, so it is better to do a log transformation here to compress the range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. 'search_type', 'device' are managable features with less cardinalilty so it is better use one hot encoding which prevent the model from assumng any ordinal relationship or frequency encoding can also used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.'day_of_week' is scaled using cyclical encoding inorder to capture the cyclical nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in PP.df_corr.columns:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        # Plotting the column values\n",
    "        plt.subplot(1, 3, 1)\n",
    "        sns.boxplot(PP.df_corr[column])\n",
    "        plt.title(column)\n",
    "        \n",
    "        # Plotting the outliers\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.boxplot(PP.df_corr[column])\n",
    "        sns.stripplot(PP.df_corr[column], color='red', marker='o', alpha=0.5)\n",
    "        plt.title(\"Outliers\")\n",
    "        \n",
    "        # Plotting the skewness\n",
    "        plt.subplot(1, 3, 3)\n",
    "        sns.histplot(PP.df_corr[column], kde=True)\n",
    "        plt.title(\"Skewness\")\n",
    "        plt.xlabel(column)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Check Correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate all scaled features( remove 'ymd','day_of_week') and labels ('is_clicked_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_scaled_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_label.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = PP.df_corr.iloc[:,:].corr()\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between features removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = PP.df_uncorr.iloc[:,:-1].corr()\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Check correlation with ground truth here 'is_clicked_item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = PP.df_uncorr.columns\n",
    "columns = [col for col in features if col != 'is_clicked_item']\n",
    "for feature in columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(PP.df_uncorr[[feature,'is_clicked_item']].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title(f'Correlation Chart for {feature} and click')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Drop features which are less important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = columns\n",
    "importances = PP.feature_imp\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Select Optimal features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP.df_independent_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With this Preprocessing is completed and the class returns df_independent_feature, df_label and df_test_independent_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model_Selection:\n",
    "    def __init__(self, df_independent_feature, df_label):\n",
    "        \"\"\"\n",
    "        Initialize with independent features and labels.\n",
    "        \"\"\"\n",
    "        self.df_independent_feature = df_independent_feature\n",
    "        self.df_label = df_label\n",
    "\n",
    "    def outlier_detection_ocsvm(self):\n",
    "        \"\"\"\n",
    "        Detect outliers using One-Class SVM and remove them from the dataset.\n",
    "        \"\"\"\n",
    "        self.x_reduced = TSNE(n_components=2, random_state=0).fit_transform(self.df_independent_feature)\n",
    "        svm = OneClassSVM(nu=0.005, gamma=1e-04)\n",
    "        svm.fit(self.x_reduced)\n",
    "        self.x_predicted = svm.predict(self.x_reduced)\n",
    "        \n",
    "        # Remove outliers\n",
    "        self.df_independent_no_out = self.df_independent_feature[self.x_predicted == 1]\n",
    "        self.df_label_no_out = self.df_label[self.x_predicted == 1]\n",
    "\n",
    "    def grid_search(self):\n",
    "        \"\"\"\n",
    "        Perform grid search to find the best model and hyperparameters.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.df_independent_no_out,\n",
    "            self.df_label_no_out,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "        y_train = y_train['is_clicked_item'].astype(int)\n",
    "        # Define parameter grids for models\n",
    "        param_grids = {\n",
    "            'Random Forest': {\n",
    "                'model': RandomForestClassifier(),\n",
    "                'params': {\n",
    "                    'min_samples_split': [10, 20, 30],\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'max_depth': [4, 5, 6, 7],\n",
    "                    'class_weight': ['balanced']\n",
    "                }\n",
    "            },\n",
    "            'Gradient Boosting': {\n",
    "                'model': GradientBoostingClassifier(),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'learning_rate': [0.01, 0.1],\n",
    "                    'max_depth': [3, 4, 5],\n",
    "                    'min_samples_split': [2, 5]\n",
    "                }\n",
    "            },\n",
    "            'AdaBoost': {\n",
    "                'model': AdaBoostClassifier(),\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100],\n",
    "                    'learning_rate': [1.0, 0.5]\n",
    "                }\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "                'params': {\n",
    "                    'n_estimators': [50, 100, 150, 200, 250, 500],\n",
    "                    'max_depth': [2, 3, 4, 6, 7, 8],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "                    'gamma': [0, 5, 10, 20, 50, 100],\n",
    "                    'scale_pos_weight': [sum(y_train == 0) / sum(y_train == 1)]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.model_results = {}\n",
    "        self.roc_curves = {}\n",
    "\n",
    "        for model_name, config in param_grids.items():\n",
    "            print(f\"Performing grid search for {model_name}\")\n",
    "            grid_search = GridSearchCV(config['model'], config['params'], cv=5, scoring='roc_auc')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            fpr, tpr, _ = roc_curve(y_test['is_clicked_item'].values.flatten(), y_pred_proba)\n",
    "            test_accuracy = auc(fpr, tpr)\n",
    "\n",
    "            # Store results\n",
    "            self.model_results[model_name] = {\n",
    "                \"best_model\": best_model,\n",
    "                \"params\": grid_search.best_params_,\n",
    "                \"test_accuracy\": test_accuracy,\n",
    "                \"train_accuracy\": grid_search.best_score_  # Average score from cross-validation\n",
    "            }\n",
    "            self.roc_curves[model_name] = {'fpr': fpr, 'tpr': tpr}\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate evaluation metrics.\n",
    "        \"\"\"\n",
    "        accuracy = accuracy_score(y_true.flatten(), y_pred)\n",
    "        precision = precision_score(y_true.flatten(), y_pred)\n",
    "        recall = recall_score(y_true.flatten(), y_pred)\n",
    "        f1 = f1_score(y_true.flatten(), y_pred)\n",
    "\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def best_model_score(self):\n",
    "        \"\"\"\n",
    "        Evaluate the best model after grid search.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.df_independent_no_out,\n",
    "            self.df_label_no_out,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        best_model_name = max(self.model_results.keys(), key=lambda k: self.model_results[k]['test_accuracy'])\n",
    "        \n",
    "        best_model = self.model_results[best_model_name]['best_model']\n",
    "        \n",
    "        # Fit the best model on training data\n",
    "        best_model.fit(X_train.values.reshape(-1,len(X_train.columns)), y_train.values.flatten())\n",
    "\n",
    "        # Predictions on test set\n",
    "        y_pred_test = best_model.predict(X_test.values.reshape(-1,len(X_test.columns)))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy, precision, recall, f1 = self.calculate_metrics(y_test['is_clicked_item'].values.flatten(), y_pred_test)\n",
    "\n",
    "        # Store metrics in DataFrame\n",
    "        self.metrics_df = pd.DataFrame({\n",
    "            'Metrics': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "            'Values': [accuracy, precision, recall, f1]\n",
    "        })\n",
    "\n",
    "    def thresholding(self):\n",
    "        \"\"\"\n",
    "        Find optimal threshold value based on evaluation metrics.\n",
    "        \"\"\"\n",
    "        thresholds = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        y_pred_prob = self.y_pred_prob[:, 1]  # Assuming second column is positive class probability\n",
    "        \n",
    "        for threshold in np.arange(0.1, 0.5, 0.01):\n",
    "            y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "            \n",
    "            f1 = f1_score(self.y_true.values.flatten(), y_pred)\n",
    "            thresholds.append(threshold)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "        # Store results in DataFrame\n",
    "        self.threshold_df = pd.DataFrame({'Threshold': thresholds,'F1 Score': f1_scores})\n",
    "        \n",
    "    def perform_threshold(self):\n",
    "        \"\"\"\n",
    "        Apply a determined threshold and calculate new evaluation metrics.\n",
    "        \"\"\"\n",
    "        threshold_value = 0.4  \n",
    "         \n",
    "        # Perform thresholding on predictions\n",
    "        y_pred_thresholded = (self.y_pred_prob[:, 1] >= threshold_value).astype(int) \n",
    "         \n",
    "        # Calculate metrics after applying threshold\n",
    "        metrics_values = {\n",
    "            'Precision': precision_score(self.y_true.values.flatten(), y_pred_thresholded),\n",
    "            'Recall': recall_score(self.y_true.values.flatten(), y_pred_thresholded),\n",
    "            'F1 Score': f1_score(self.y_true.values.flatten(), y_pred_thresholded),\n",
    "            'Accuracy': accuracy_score(self.y_true.values.flatten(), y_pred_thresholded)\n",
    "        }\n",
    "\n",
    "        # Store results in DataFrame\n",
    "        self.thresholded_metrics_df = pd.DataFrame.from_dict(metrics_values , orient='index', columns=['Score'])\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Execute the full process of outlier detection and model selection.\n",
    "        \"\"\"\n",
    "        self.outlier_detection_ocsvm()\n",
    "        self.grid_search()\n",
    "        self.best_model_score()\n",
    "        #self.thresholding()\n",
    "        #self.perform_threshold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS = Model_Selection(df_independent_feature, df_label)\n",
    "MS.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Outlier detection and removal outliers \n",
    "### Method here uses t-SNE to reduce the dimensionality of the independent features to two dimensions. Then fit a One-class SVM model to predict outliers. Finally it remove outliers from both independent features and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Grid search to find the best model and its hyperparameters\n",
    "### Data splitting:- splits the dataset into train and validation set\n",
    "### Parameter grids:- define parameter grids for different models (Random Forest, Gradient Boosting, Adaboost, XGBoost)\n",
    "### Grid Search:- For each model, it perform a grid search using cross-validation to find the best hyperparamter based on ROC AUC score\n",
    "### Result:- It saves the best model, paramters, test accuracy, and ROC curve for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_val, y_train, y_val = train_test_split(\n",
    "            MS.df_independent_no_out,\n",
    "            MS.df_label_no_out,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS.model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(MS.model_results.keys(), key=lambda k: MS.model_results[k]['test_accuracy'])\n",
    "        \n",
    "best_model = MS.model_results[best_model_name]['best_model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Evaluation Metrics\n",
    "### Evaluation metrics used are accuracy, precision, recall and F1 score.\n",
    "### Here evaluation is done making use of true labels in validation set and predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train.values.reshape(-1,len(X_train.columns)), y_train.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = best_model.predict(X_val.values.reshape(-1,len(X_val.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob =best_model.predict_proba(X_val)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Best Model Evaluation\n",
    "### Evaluates the best model obtained from grid search on a validation set\n",
    "### Identify best model, by selecting the highest training accuracy\n",
    "### Then it makes predictions on the validation set and calculate evaluation metrics\n",
    "### save metrics as a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS.metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS.roc_curves(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Thresholding \n",
    "### Finds the optimal threshold value for calssification based on F1 score\n",
    "### Iterate over possible threshold values\n",
    "### calcuate F1 score for each threshold\n",
    "### store results in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "y_true = y_val\n",
    "for threshold in np.arange(0.01, 0.2, 0.01):\n",
    "    y_pred = (y_pred_prob >= threshold)*1\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    thresholds.append(threshold)\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "threshold_df = pd.DataFrame({'Threshold': thresholds, 'F1': f1_scores, 'Precison': precision_scores, 'Recall': recall_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_df.plot(x=\"Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Prediction in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make test data similar to training data format to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_reduced = TSNE(n_components=2, random_state=0).fit_transform(df_test_independent_feature)\n",
    "svm = OneClassSVM(nu=0.005, gamma=1e-04)\n",
    "svm.fit(test_data_reduced)\n",
    "# Predict outliers using the trained One-Class SVM\n",
    "test_data_predicted = svm.predict(test_data_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test data and predict the probability of click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob = best_model.predict_proba(df_test_independent_feature)[:,1]  # Probability for the positive class\n",
    "# Apply the threshold to classify\n",
    "y_test_pred_class = (y_test_pred_prob >= optimal_threshold).astype(int)\n",
    "    \n",
    "# Combine results into a DataFrame\n",
    "predictions = pd.DataFrame({\n",
    "    'Predicted_Probability': y_test_pred_prob,\n",
    "    'Predicted_Class': y_test_pred_class\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the result as csv file with columns 'user_id', 'search_id','item_id', and 'prob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prediction =PP.df_test.iloc[:,1:4]\n",
    "df_test_prediction['prob'] = y_test_pred_prob\n",
    "df_test_prediction.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prediction.to_csv('/Users/athirapulickakudysalin/Documents/Job_search/Trivago/Ranking/case-study/prediction_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
